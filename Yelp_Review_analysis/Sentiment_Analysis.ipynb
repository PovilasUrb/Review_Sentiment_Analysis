{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**: https://www.kaggle.com/datasets/ilhamfp31/yelp-review-dataset/data"
      ],
      "metadata": {
        "id": "kW1Px2Jh6HNd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:56:29.457485Z",
          "iopub.status.busy": "2024-03-16T02:56:29.45704Z",
          "iopub.status.idle": "2024-03-16T02:56:35.866235Z",
          "shell.execute_reply": "2024-03-16T02:56:35.865293Z",
          "shell.execute_reply.started": "2024-03-16T02:56:29.457457Z"
        },
        "trusted": true,
        "id": "a2YRoAWQyS-Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from argparse import Namespace\n",
        "import collections\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOgiAfOWyZzw",
        "outputId": "3b346344-81af-476e-b429-28d981ef2b88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:56:35.868744Z",
          "iopub.status.busy": "2024-03-16T02:56:35.868286Z",
          "iopub.status.idle": "2024-03-16T02:56:35.874169Z",
          "shell.execute_reply": "2024-03-16T02:56:35.873223Z",
          "shell.execute_reply.started": "2024-03-16T02:56:35.868717Z"
        },
        "trusted": true,
        "id": "KBbZtSOWyS-R"
      },
      "outputs": [],
      "source": [
        "args = Namespace(\n",
        "    raw_train_dataset_csv=\"drive/MyDrive/Colab/Yelp/train.csv\",\n",
        "    raw_test_dataset_csv=\"drive/MyDrive/Colab/Yelp/test.csv\",\n",
        "    proportion_subset_of_train=0.1,\n",
        "    train_proportion=0.7,\n",
        "    val_proportion=0.15,\n",
        "    test_proportion=0.15,\n",
        "    output_munged_csv=\"reviews_with_splits_lite.csv\",\n",
        "    seed=1337\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:56:35.877061Z",
          "iopub.status.busy": "2024-03-16T02:56:35.875774Z",
          "iopub.status.idle": "2024-03-16T02:56:45.743619Z",
          "shell.execute_reply": "2024-03-16T02:56:45.742373Z",
          "shell.execute_reply.started": "2024-03-16T02:56:35.877025Z"
        },
        "trusted": true,
        "id": "jqebzx7gyS-S"
      },
      "outputs": [],
      "source": [
        "# Read raw data\n",
        "train_reviews = pd.read_csv(args.raw_train_dataset_csv, header=None, names=['rating', 'review'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:56:45.746957Z",
          "iopub.status.busy": "2024-03-16T02:56:45.746581Z",
          "iopub.status.idle": "2024-03-16T02:57:33.543489Z",
          "shell.execute_reply": "2024-03-16T02:57:33.542532Z",
          "shell.execute_reply.started": "2024-03-16T02:56:45.74691Z"
        },
        "trusted": true,
        "id": "Tu48MNWPyS-S"
      },
      "outputs": [],
      "source": [
        "# Select 10% of data\n",
        "by_rating = collections.defaultdict(list)\n",
        "for _, row in train_reviews.iterrows():\n",
        "    by_rating[row.rating].append(row.to_dict())\n",
        "\n",
        "review_subset = []\n",
        "\n",
        "for _, item_list in sorted(by_rating.items()):\n",
        "\n",
        "    n_total = len(item_list)\n",
        "    n_subset = int(args.proportion_subset_of_train * n_total)\n",
        "    review_subset.extend(item_list[:n_subset])\n",
        "\n",
        "review_subset = pd.DataFrame(review_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:33.545178Z",
          "iopub.status.busy": "2024-03-16T02:57:33.544793Z",
          "iopub.status.idle": "2024-03-16T02:57:38.531166Z",
          "shell.execute_reply": "2024-03-16T02:57:38.529716Z",
          "shell.execute_reply.started": "2024-03-16T02:57:33.545143Z"
        },
        "trusted": true,
        "id": "rAxRWTfVyS-S"
      },
      "outputs": [],
      "source": [
        "# Splitting the subset by rating to create our new train, val, and test splits\n",
        "by_rating = collections.defaultdict(list)\n",
        "for _, row in review_subset.iterrows():\n",
        "    by_rating[row.rating].append(row.to_dict())\n",
        "\n",
        "final_list = []\n",
        "np.random.seed(args.seed)\n",
        "\n",
        "for _, item_list in sorted(by_rating.items()):\n",
        "\n",
        "    np.random.shuffle(item_list)\n",
        "\n",
        "    n_total = len(item_list)\n",
        "    n_train = int(args.train_proportion * n_total)\n",
        "    n_val = int(args.val_proportion * n_total)\n",
        "    n_test = int(args.test_proportion * n_total)\n",
        "\n",
        "    # Give data point a split attribute\n",
        "    for item in item_list[:n_train]:\n",
        "        item['split'] = 'train'\n",
        "\n",
        "    for item in item_list[n_train:n_train+n_val]:\n",
        "        item['split'] = 'val'\n",
        "\n",
        "    for item in item_list[n_train+n_val:n_train+n_val+n_test]:\n",
        "        item['split'] = 'test'\n",
        "\n",
        "    final_list.extend(item_list)\n",
        "\n",
        "final_reviews = pd.DataFrame(final_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:38.533105Z",
          "iopub.status.busy": "2024-03-16T02:57:38.532684Z",
          "iopub.status.idle": "2024-03-16T02:57:38.545622Z",
          "shell.execute_reply": "2024-03-16T02:57:38.544342Z",
          "shell.execute_reply.started": "2024-03-16T02:57:38.533067Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvOdrS34yS-S",
        "outputId": "27e72e0c-3a5f-4ab3-8f80-3886156b09f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56000, 3)\n",
            "   rating                                             review  split\n",
            "0       1  Terrible place to work for I just heard a stor...  train\n",
            "1       1  3 hours, 15 minutes-- total time for an extrem...  train\n",
            "2       1  My less than stellar review is for service.   ...  train\n",
            "3       1  I'm granting one star because there's no way t...  train\n",
            "4       1  The food here is mediocre at best. I went afte...  train\n"
          ]
        }
      ],
      "source": [
        "print(final_reviews.shape)\n",
        "print(final_reviews.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:38.548203Z",
          "iopub.status.busy": "2024-03-16T02:57:38.547441Z",
          "iopub.status.idle": "2024-03-16T02:57:45.375756Z",
          "shell.execute_reply": "2024-03-16T02:57:45.374686Z",
          "shell.execute_reply.started": "2024-03-16T02:57:38.548162Z"
        },
        "trusted": true,
        "id": "J9rEWoJvyS-S"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
        "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
        "    return text\n",
        "\n",
        "final_reviews.review = final_reviews.review.apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:45.377851Z",
          "iopub.status.busy": "2024-03-16T02:57:45.377454Z",
          "iopub.status.idle": "2024-03-16T02:57:45.390512Z",
          "shell.execute_reply": "2024-03-16T02:57:45.3892Z",
          "shell.execute_reply.started": "2024-03-16T02:57:45.377813Z"
        },
        "trusted": true,
        "id": "wJQhZDhNyS-S"
      },
      "outputs": [],
      "source": [
        "# Mapping positive and negative reviews\n",
        "mapping_dict = {1 : 'Negative', 2 : 'Positive'}\n",
        "final_reviews['rating'] = final_reviews['rating'].map(mapping_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:45.393205Z",
          "iopub.status.busy": "2024-03-16T02:57:45.39201Z",
          "iopub.status.idle": "2024-03-16T02:57:45.411395Z",
          "shell.execute_reply": "2024-03-16T02:57:45.41025Z",
          "shell.execute_reply.started": "2024-03-16T02:57:45.393172Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qYJqudYFyS-S",
        "outputId": "eb01abcc-52ad-43d4-e2aa-8080efee0f9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     rating                                             review  split\n",
              "0  Negative  terrible place to work for i just heard a stor...  train\n",
              "1  Negative   hours , minutes total time for an extremely s...  train\n",
              "2  Negative  my less than stellar review is for service . w...  train\n",
              "3  Negative  i m granting one star because there s no way t...  train\n",
              "4  Negative  the food here is mediocre at best . i went aft...  train"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-803fde27-055a-4924-8768-8ca4f5803e78\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Negative</td>\n",
              "      <td>terrible place to work for i just heard a stor...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Negative</td>\n",
              "      <td>hours , minutes total time for an extremely s...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Negative</td>\n",
              "      <td>my less than stellar review is for service . w...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Negative</td>\n",
              "      <td>i m granting one star because there s no way t...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Negative</td>\n",
              "      <td>the food here is mediocre at best . i went aft...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-803fde27-055a-4924-8768-8ca4f5803e78')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-803fde27-055a-4924-8768-8ca4f5803e78 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-803fde27-055a-4924-8768-8ca4f5803e78');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-df48b900-8479-4a97-bb76-e38a43e0b3c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df48b900-8479-4a97-bb76-e38a43e0b3c5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-df48b900-8479-4a97-bb76-e38a43e0b3c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_reviews",
              "summary": "{\n  \"name\": \"final_reviews\",\n  \"rows\": 56000,\n  \"fields\": [\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Positive\",\n          \"Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 55993,\n        \"samples\": [\n          \"this company is great ! i would give then stars if i could . we moved into a new house easter weekend and discovered it was infested with ticks . i called sam the bug man and they not only knew what to do right off the bat , they came out and did it the same day sat before easter . they were really nice and went out of their way to come out on short notice on a holiday weekend . i will be using them regularly . don t hesitate to call them ! \",\n          \"this is a depressing coffee shop . i went in on a wednesday afternoon to find the place dim , muggy , eerily silent as in no music or talk , just shuffling noises , and filled with a sense of sadness . i tried to sit down and enjoy some coffee , which was drinkable , but i couldn t get over the odd atmosphere , that is until the music started , so quiet i couldn t even tell you what it was , just that it was on . i m giving it two stars for the awesome alternative energy posters hanging on the far wall . \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\",\n          \"val\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "final_reviews.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:48.086927Z",
          "iopub.status.busy": "2024-03-16T02:57:48.086554Z",
          "iopub.status.idle": "2024-03-16T02:57:50.020648Z",
          "shell.execute_reply": "2024-03-16T02:57:50.019327Z",
          "shell.execute_reply.started": "2024-03-16T02:57:48.086899Z"
        },
        "trusted": true,
        "id": "sAe_CRuEyS-S"
      },
      "outputs": [],
      "source": [
        "final_reviews.to_csv(\"drive/MyDrive/Colab/Yelp/reviews_with_splits.csv\",index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:51.313957Z",
          "iopub.status.busy": "2024-03-16T02:57:51.313579Z",
          "iopub.status.idle": "2024-03-16T02:57:51.328744Z",
          "shell.execute_reply": "2024-03-16T02:57:51.327567Z",
          "shell.execute_reply.started": "2024-03-16T02:57:51.313929Z"
        },
        "trusted": true,
        "id": "9Gn5rmRgyS-T"
      },
      "outputs": [],
      "source": [
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, review_df, vectorizer):\n",
        "        self.review_df = review_df\n",
        "        self._vectorizer = vectorizer\n",
        "\n",
        "        self.train_df = self.review_df[self.review_df.split == 'train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.review_df[self.review_df.split == \"val\"]\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.review_df[self.review_df.split == \"test\"]\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        self._lookup_dict = {'train' : (self.train_df, self.train_size),\n",
        "                             'val' : (self.val_df, self.validation_size),\n",
        "                             'test' : (self.test_df, self.test_size)}\n",
        "        self.set_split('train')\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, review_csv):\n",
        "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
        "        Args:\n",
        "            review_csv (str): location of the dataset\n",
        "        Returns:\n",
        "            an instance of ReviewDataset\n",
        "        \"\"\"\n",
        "        review_df = pd.read_csv(review_csv)\n",
        "        return cls(review_df,ReviewVectorizer.from_dataframe(review_df))\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" returns the vectorizer\"\"\"\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        \"\"\" selects the splits in the dataset using a column in the dataframe\n",
        "        Args:\n",
        "            split (str): one of \"train\", \"val\", or \"test\"\n",
        "        \"\"\"\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\n",
        "        Args:\n",
        "            index (int): the index to the data point\n",
        "        Returns:\n",
        "            a dict of the data point's features (x_data) and label (y_target)\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "        review_vector = self._vectorizer.vectorize(row.review)\n",
        "        rating_index = self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
        "        return {'x_data' : review_vector,\n",
        "               'y_target' : rating_index}\n",
        "\n",
        "    def get_num_batches(self,batch_size):\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
        "        Args:\n",
        "            batch_size (int)\n",
        "        Returns:\n",
        "            number of batches in the dataset\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:52.16901Z",
          "iopub.status.busy": "2024-03-16T02:57:52.168634Z",
          "iopub.status.idle": "2024-03-16T02:57:52.183852Z",
          "shell.execute_reply": "2024-03-16T02:57:52.182679Z",
          "shell.execute_reply.started": "2024-03-16T02:57:52.168983Z"
        },
        "trusted": true,
        "id": "YtPVnLQ_yS-T"
      },
      "outputs": [],
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"Class to process text and extract Vocabulary for mapping\"\"\"\n",
        "\n",
        "    def __init__(self, token_to_idx = None, add_unk = True, unk_token = \"<UNK>\"):\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx:token for token, idx in self._token_to_idx.items()}\n",
        "\n",
        "        self._add_unk = add_unk\n",
        "        self._unk_token = unk_token\n",
        "\n",
        "        self.unk_index = -1\n",
        "        if add_unk:\n",
        "            self.unk_index = self.add_token(unk_token)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
        "        return {'token_to_idx': self._token_to_idx,\n",
        "                'add_unk': self._add_unk,\n",
        "                'unk_token': self._unk_token}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        \"\"\"Update mapping dicts based on the token.\n",
        "        Args:\n",
        "            token (str): the item to add into the Vocabulary\n",
        "        Returns:\n",
        "            index (int): the integer corresponding to the token\n",
        "        \"\"\"\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token or the UNK index if token isn't present.\n",
        "        Args:\n",
        "            token (str): the token to look up\n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        Notes:\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary)\n",
        "            for the UNK functionality\n",
        "        \"\"\"\n",
        "\n",
        "        if self._add_unk:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\"Return the token associated with the index\n",
        "        Args:\n",
        "            index (int): the index to look up\n",
        "        Returns:\n",
        "            token (str): the token corresponding to the index\n",
        "        Raises:\n",
        "            KeyError: if the index is not in the Vocabulary\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:53.057421Z",
          "iopub.status.busy": "2024-03-16T02:57:53.056976Z",
          "iopub.status.idle": "2024-03-16T02:57:53.073017Z",
          "shell.execute_reply": "2024-03-16T02:57:53.071795Z",
          "shell.execute_reply.started": "2024-03-16T02:57:53.057346Z"
        },
        "trusted": true,
        "id": "88jA3RDvyS-T"
      },
      "outputs": [],
      "source": [
        "class ReviewVectorizer(object):\n",
        "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
        "\n",
        "    def __init__(self, review_vocab, rating_vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            review_vocab (Vocabulary): maps words to integers\n",
        "            rating_vocab (Vocabulary): maps class labels to integers\n",
        "        \"\"\"\n",
        "        self.review_vocab = review_vocab\n",
        "        self.rating_vocab = rating_vocab\n",
        "\n",
        "    def vectorize(self, review):\n",
        "        \"\"\"Create a collapsed one-hot vector for the review\n",
        "        Args:\n",
        "            review (str): the review\n",
        "        Returns:\n",
        "            one_hot (np.ndarray): the collapsed one-hot encoding\n",
        "        \"\"\"\n",
        "        one_hot = np.zeros(len(self.review_vocab), dtype = np.float32)\n",
        "\n",
        "        for token in review.split(\" \"):\n",
        "            if token not in string.punctuation:\n",
        "                one_hot[self.review_vocab.lookup_token(token)] = 1\n",
        "        return one_hot\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, review_df, cutoff = 25):\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
        "        Args:\n",
        "            review_df (pandas.DataFrame): the review dataset\n",
        "            cutoff (int): the parameter for frequency­based filtering\n",
        "        Returns:\n",
        "            an instance of the ReviewVectorizer\n",
        "        \"\"\"\n",
        "        review_vocab = Vocabulary(add_unk = True)\n",
        "        rating_vocab = Vocabulary(add_unk = False)\n",
        "\n",
        "        # Add ratings\n",
        "        for rating in sorted(set(set(review_df.rating))):\n",
        "            rating_vocab.add_token(rating)\n",
        "\n",
        "        #Add top words if count > cutoff\n",
        "        word_counts = Counter()\n",
        "        for review in review_df.review:\n",
        "            for word in review.split(\" \"):\n",
        "                if word not in string.punctuation:\n",
        "                    word_counts[word] += 1\n",
        "\n",
        "        for word, count in word_counts.items():\n",
        "            if count > cutoff:\n",
        "                review_vocab.add_token(word)\n",
        "\n",
        "        return cls(review_vocab, rating_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\"Intantiate a ReviewVectorizer from a serializable dictionary\n",
        "        Args:\n",
        "            contents (dict): the serializable dictionary\n",
        "        Returns:\n",
        "            an instance of the ReviewVectorizer class\n",
        "        \"\"\"\n",
        "        review_vocab = Vocabulary.from_serializable(contents['review_vocab'])\n",
        "        rating_vocab = Vocabulary.from_serializable(contents['rating_vocab'])\n",
        "        return cls(review_vocab=review_vocab, rating_vocab=rating_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        \"\"\"Create the serializable dictionary for caching\n",
        "        Returns:\n",
        "            contents (dict): the serializable dictionary\n",
        "        \"\"\"\n",
        "        return {'review_vocab': self.review_vocab.to_serializable(),\n",
        "        'rating_vocab': self.rating_vocab.to_serializable()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:53.940247Z",
          "iopub.status.busy": "2024-03-16T02:57:53.939865Z",
          "iopub.status.idle": "2024-03-16T02:57:53.947463Z",
          "shell.execute_reply": "2024-03-16T02:57:53.946112Z",
          "shell.execute_reply.started": "2024-03-16T02:57:53.940218Z"
        },
        "trusted": true,
        "id": "kwwFZT7IyS-T"
      },
      "outputs": [],
      "source": [
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    A generator function which wraps the PyTorch DataLoader. It will\n",
        "      ensure each tensor is on the write device location.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:54.801877Z",
          "iopub.status.busy": "2024-03-16T02:57:54.801499Z",
          "iopub.status.idle": "2024-03-16T02:57:54.810307Z",
          "shell.execute_reply": "2024-03-16T02:57:54.809412Z",
          "shell.execute_reply.started": "2024-03-16T02:57:54.80185Z"
        },
        "trusted": true,
        "id": "gKvjVI_TyS-T"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ReviewClassifier(nn.Module):\n",
        "    \"\"\" a simple perceptron based classifier\"\"\"\n",
        "    def __init__(self, num_features):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_features (int): the size of the input feature vector\n",
        "        \"\"\"\n",
        "        super(ReviewClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_features = num_features,\n",
        "                            out_features = 1)\n",
        "\n",
        "    def forward(self, x_in, apply_sigmoid=False):\n",
        "        \"\"\"The forward pass of the classifier\n",
        "        Args:\n",
        "            x_in (torch.Tensor): an input data tensor\n",
        "            x_in.shape should be (batch, num_features)\n",
        "            apply_sigmoid (bool): a flag for the sigmoid activation\n",
        "                                should be false if used with the cross­entropy losses\n",
        "        Returns:\n",
        "            the resulting tensor. tensor.shape should be (batch,).\n",
        "        \"\"\"\n",
        "        y_out = self.fc1(x_in).squeeze()\n",
        "        if apply_sigmoid:\n",
        "            y_out = F.sigmoid(y_out)\n",
        "        return y_out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:56.102885Z",
          "iopub.status.busy": "2024-03-16T02:57:56.102461Z",
          "iopub.status.idle": "2024-03-16T02:57:56.109194Z",
          "shell.execute_reply": "2024-03-16T02:57:56.108168Z",
          "shell.execute_reply.started": "2024-03-16T02:57:56.102855Z"
        },
        "trusted": true,
        "id": "TcdOQ5GdyS-U"
      },
      "outputs": [],
      "source": [
        "args = Namespace(\n",
        "    # Data and path information\n",
        "    frequency_cutoff=25,\n",
        "    model_state_file='model.pth',\n",
        "    review_csv='drive/MyDrive/Colab/Yelp/reviews_with_splits.csv',\n",
        "    save_dir='model_storage/ch3/yelp/',\n",
        "    vectorizer_file='vectorizer.json',\n",
        "    # No model hyperparameters\n",
        "    # Training hyperparameters\n",
        "    batch_size=128,\n",
        "    early_stopping_criteria=5,\n",
        "    learning_rate=0.001,\n",
        "    num_epochs=10,\n",
        "    seed=1337,\n",
        "    cuda = True\n",
        "    # Runtime options omitted for space\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:57.103009Z",
          "iopub.status.busy": "2024-03-16T02:57:57.1026Z",
          "iopub.status.idle": "2024-03-16T02:57:57.11092Z",
          "shell.execute_reply": "2024-03-16T02:57:57.109646Z",
          "shell.execute_reply.started": "2024-03-16T02:57:57.102979Z"
        },
        "trusted": true,
        "id": "3Ue8tqvOyS-U"
      },
      "outputs": [],
      "source": [
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)\n",
        "\n",
        "def compute_accuracy(y_pred, y_target):\n",
        "    y_target = y_target.cpu()\n",
        "    y_pred_indices = (torch.sigmoid(y_pred)>0.5).cpu().long()#.max(dim=1)[1]\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:57:58.257924Z",
          "iopub.status.busy": "2024-03-16T02:57:58.257516Z",
          "iopub.status.idle": "2024-03-16T02:58:06.321557Z",
          "shell.execute_reply": "2024-03-16T02:58:06.319952Z",
          "shell.execute_reply.started": "2024-03-16T02:57:58.257892Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhJ7IXH-yS-U",
        "outputId": "ef9b6432-92b8-4808-c1a8-f2233ae9961e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA: False\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def make_train_state(args):\n",
        "    return {'epoch_index' : 0,\n",
        "            'train_loss' : [],\n",
        "            'train_acc' : [],\n",
        "            'val_loss' : [],\n",
        "            'val_acc' : [],\n",
        "            'test_loss' : -1,\n",
        "            'test_acc' : -1}\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "\n",
        "print(\"Using CUDA: {}\".format(args.cuda))\n",
        "\n",
        "# handle dirs\n",
        "handle_dirs(args.save_dir)\n",
        "\n",
        "\n",
        "# dataset and vectorizer\n",
        "dataset = ReviewDataset.load_dataset_and_make_vectorizer(args.review_csv)\n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "# model\n",
        "classifier = ReviewClassifier(num_features = len(vectorizer.review_vocab))\n",
        "classifier = classifier.to(args.device)\n",
        "\n",
        "# Loass and optimizer\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr = args.learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T02:58:06.324916Z",
          "iopub.status.busy": "2024-03-16T02:58:06.324219Z",
          "iopub.status.idle": "2024-03-16T03:00:05.184254Z",
          "shell.execute_reply": "2024-03-16T03:00:05.183014Z",
          "shell.execute_reply.started": "2024-03-16T02:58:06.324873Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzNtMqWEyS-U",
        "outputId": "fde50d99-3d58-4e24-f17c-c2009775a290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch # 0 : Train Loss : 0.48157445531265414 Train accuracy : 83.9103349673203\n",
            "Epoch # 0 : Val Loss : 0.3813157329192529 Val accuracy : 88.62980769230768\n",
            "Epoch # 1 : Train Loss : 0.32947911448728007 Train accuracy : 90.26756535947712\n",
            "Epoch # 1 : Val Loss : 0.30913234628163844 Val accuracy : 90.31249999999999\n",
            "Epoch # 2 : Train Loss : 0.2745377444753463 Train accuracy : 91.71772875816993\n",
            "Epoch # 2 : Val Loss : 0.2735499019806201 Val accuracy : 91.26201923076923\n",
            "Epoch # 3 : Train Loss : 0.24356742695071337 Train accuracy : 92.39174836601306\n",
            "Epoch # 3 : Val Loss : 0.252897524375182 Val accuracy : 91.77884615384616\n",
            "Epoch # 4 : Train Loss : 0.222848537603235 Train accuracy : 92.83854166666671\n",
            "Epoch # 4 : Val Loss : 0.23897184706651242 Val accuracy : 91.95913461538463\n",
            "Epoch # 5 : Train Loss : 0.20773092720633238 Train accuracy : 93.28533496732028\n",
            "Epoch # 5 : Val Loss : 0.22973635746882506 Val accuracy : 92.03124999999997\n",
            "Epoch # 6 : Train Loss : 0.19574191508924263 Train accuracy : 93.61468545751637\n",
            "Epoch # 6 : Val Loss : 0.2226785698762306 Val accuracy : 92.33173076923076\n",
            "Epoch # 7 : Train Loss : 0.18628557902925147 Train accuracy : 93.83935866013074\n",
            "Epoch # 7 : Val Loss : 0.21821145461155822 Val accuracy : 92.24759615384617\n",
            "Epoch # 8 : Train Loss : 0.17812084153391958 Train accuracy : 94.07169117647055\n",
            "Epoch # 8 : Val Loss : 0.2135778981905717 Val accuracy : 92.4278846153846\n",
            "Epoch # 9 : Train Loss : 0.17138829374430237 Train accuracy : 94.29636437908503\n",
            "Epoch # 9 : Val Loss : 0.21002089931414675 Val accuracy : 92.2956730769231\n"
          ]
        }
      ],
      "source": [
        "for epoch_index in range(args.num_epochs):\n",
        "    train_state[\"epoch_indx\"] = epoch_index\n",
        "\n",
        "    # Iterate over training dataset\n",
        "\n",
        "    # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "    dataset.set_split(\"train\")\n",
        "    batch_generator = generate_batches(dataset, batch_size = args.batch_size,\n",
        "                                      device = args.device)\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    classifier.train()\n",
        "\n",
        "    for batch_index, batch_dict in enumerate(batch_generator):\n",
        "        # Training routine is 5 steps\n",
        "\n",
        "        # Step 1 : zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Step 2 : compute the output\n",
        "        y_pred = classifier(x_in = batch_dict['x_data'].float())\n",
        "\n",
        "        # Step 3 : compute the loss\n",
        "        loss = loss_func(y_pred, batch_dict[\"y_target\"].float())\n",
        "        loss_batch = loss.item()\n",
        "        running_loss += (loss_batch - running_loss)/(batch_index + 1)\n",
        "\n",
        "        # Step 4 : use loss to produce gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Step 5 : use optimizer to take gradient step\n",
        "        optimizer.step()\n",
        "\n",
        "        # -----------------------------------------------\n",
        "        # Compute the accuracy\n",
        "        acc_batch = compute_accuracy(y_pred, batch_dict[\"y_target\"])\n",
        "        running_acc += (acc_batch - running_acc) / (batch_index + 1)\n",
        "\n",
        "    train_state[\"train_loss\"].append(running_loss)\n",
        "    train_state[\"train_acc\"].append(running_acc)\n",
        "    print(\"Epoch # {0} : Train Loss : {1} Train accuracy : {2}\".format(epoch_index, running_loss, running_acc))\n",
        "\n",
        "    # Iterate over val dataset\n",
        "    # setup: batch generator, set loss and acc to 0, set eval mode on\n",
        "    dataset.set_split('val')\n",
        "    batch_generator = generate_batches(dataset,\n",
        "                                        batch_size=args.batch_size,\n",
        "                                        device=args.device)\n",
        "    running_loss = 0.\n",
        "    running_acc = 0.\n",
        "    classifier.eval()\n",
        "\n",
        "    for batch_index, batch_dict in enumerate(batch_generator):\n",
        "        # Step 1 : compute the output\n",
        "        y_pred = classifier(x_in = batch_dict[\"x_data\"].float())\n",
        "\n",
        "        # Step 2 : compute the loss\n",
        "        loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
        "        loss_batch = loss.item()\n",
        "        running_loss += (loss_batch - running_loss) / (batch_index + 1)\n",
        "\n",
        "        # step 3. compute the accuracy\n",
        "        acc_batch = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "        running_acc += (acc_batch - running_acc) / (batch_index + 1)\n",
        "\n",
        "    train_state['val_loss'].append(running_loss)\n",
        "    train_state['val_acc'].append(running_acc)\n",
        "    print(\"Epoch # {0} : Val Loss : {1} Val accuracy : {2}\".format(epoch_index, running_loss, running_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T03:00:05.186753Z",
          "iopub.status.busy": "2024-03-16T03:00:05.185948Z",
          "iopub.status.idle": "2024-03-16T03:00:07.276428Z",
          "shell.execute_reply": "2024-03-16T03:00:07.275295Z",
          "shell.execute_reply.started": "2024-03-16T03:00:05.186721Z"
        },
        "trusted": true,
        "id": "YZGC7oklyS-U"
      },
      "outputs": [],
      "source": [
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset,\n",
        "                                    batch_size=args.batch_size,\n",
        "                                    device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
        "    # compute the loss\n",
        "    loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
        "    loss_batch = loss.item()\n",
        "    running_loss += (loss_batch - running_loss) / (batch_index + 1)\n",
        "    # compute the accuracy\n",
        "    acc_batch = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "    running_acc += (acc_batch - running_acc) / (batch_index + 1)\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T03:00:07.278726Z",
          "iopub.status.busy": "2024-03-16T03:00:07.278345Z",
          "iopub.status.idle": "2024-03-16T03:00:07.285566Z",
          "shell.execute_reply": "2024-03-16T03:00:07.284209Z",
          "shell.execute_reply.started": "2024-03-16T03:00:07.278694Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGIzFuZgyS-U",
        "outputId": "8ad1082e-831d-48db-d62b-33cab89ff40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.215\n",
            "Test Accuracy: 91.95\n"
          ]
        }
      ],
      "source": [
        "print(\"Test loss: {:.3f}\".format(train_state['test_loss']))\n",
        "print(\"Test Accuracy: {:.2f}\".format(train_state['test_acc']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T03:00:12.802139Z",
          "iopub.status.busy": "2024-03-16T03:00:12.801373Z",
          "iopub.status.idle": "2024-03-16T03:00:12.812785Z",
          "shell.execute_reply": "2024-03-16T03:00:12.811545Z",
          "shell.execute_reply.started": "2024-03-16T03:00:12.802093Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIkhbnk2yS-U",
        "outputId": "fe934428-d123-49f2-9f11-9ed26d9a117c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is a pretty awesome book -> Positive\n"
          ]
        }
      ],
      "source": [
        "def predict_rating(review, classifier, vectorizer,decision_threshold=0.5):\n",
        "    \"\"\"Predict the rating of a review\n",
        "    Args:\n",
        "        review (str): the text of the review\n",
        "        classifier (ReviewClassifier): the trained model\n",
        "        vectorizer (ReviewVectorizer): the corresponding vectorizer\n",
        "        decision_threshold (float): The numerical boundary which\n",
        "                                    separates the rating classes\n",
        "    \"\"\"\n",
        "    classifier = classifier#.to('cuda')\n",
        "    review = preprocess_text(review)\n",
        "    vectorized_review = torch.tensor(vectorizer.vectorize(review))#.to('cuda')\n",
        "    result = classifier(vectorized_review.view(1, -1))\n",
        "    probability_value = F.sigmoid(result).item()\n",
        "    index = 1\n",
        "    if probability_value < decision_threshold:\n",
        "        index = 0\n",
        "    return vectorizer.rating_vocab.lookup_index(index)\n",
        "test_review = \"this is a pretty awesome book\"\n",
        "prediction = predict_rating(test_review, classifier, vectorizer)\n",
        "print(f\"{test_review} -> {prediction}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T03:00:16.760674Z",
          "iopub.status.busy": "2024-03-16T03:00:16.759662Z",
          "iopub.status.idle": "2024-03-16T03:00:16.778621Z",
          "shell.execute_reply": "2024-03-16T03:00:16.777538Z",
          "shell.execute_reply.started": "2024-03-16T03:00:16.760635Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_-m_Wq7yS-U",
        "outputId": "1d9f6c10-052b-477b-d3b6-ba6a8013d5e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Influential words in Positive Reviews:\n",
            "­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­\n",
            "delicious\n",
            "amazing\n",
            "great\n",
            "fantastic\n",
            "vegas\n",
            "excellent\n",
            "awesome\n",
            "perfect\n",
            "love\n",
            "yummy\n",
            "pleasantly\n",
            "yum\n",
            "wonderful\n",
            "best\n",
            "ngreat\n",
            "favorite\n",
            "reasonable\n",
            "solid\n",
            "loved\n",
            "helpful\n"
          ]
        }
      ],
      "source": [
        "# Sort weights\n",
        "fc1_weights = classifier.fc1.weight.detach()[0].cpu()\n",
        "_, indices = torch.sort(fc1_weights, dim=0, descending=True)\n",
        "indices = indices.numpy().tolist()\n",
        "\n",
        "# Top 20 words\n",
        "print(\"Influential words in Positive Reviews:\")\n",
        "print(\"­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­\")\n",
        "for i in range(20):\n",
        "    print(vectorizer.review_vocab.lookup_index(indices[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-16T03:00:20.298756Z",
          "iopub.status.busy": "2024-03-16T03:00:20.297591Z",
          "iopub.status.idle": "2024-03-16T03:00:20.30509Z",
          "shell.execute_reply": "2024-03-16T03:00:20.303921Z",
          "shell.execute_reply.started": "2024-03-16T03:00:20.298718Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-hiNzWNyS-U",
        "outputId": "af897c06-d684-4b92-c052-35d8e1e5801a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Influential words in Negative Reviews:\n",
            "­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­\n",
            "worst\n",
            "mediocre\n",
            "bland\n",
            "horrible\n",
            "rude\n",
            "terrible\n",
            "awful\n",
            "meh\n",
            "overpriced\n",
            "tasteless\n",
            "disgusting\n",
            "disappointing\n",
            "dirty\n",
            "ok\n",
            "not\n",
            "poor\n",
            "poorly\n",
            "disappointment\n",
            "elsewhere\n",
            "unfriendly\n"
          ]
        }
      ],
      "source": [
        "# Top 20 negative words\n",
        "print(\"Influential words in Negative Reviews:\")\n",
        "print(\"­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­\")\n",
        "indices.reverse()\n",
        "for i in range(20):\n",
        "    print(vectorizer.review_vocab.lookup_index(indices[i]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model_path = \"drive/MyDrive/Colab/Yelp/model.pth\"\n",
        "torch.save(classifier.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "_rVUcP5O4Foa"
      },
      "execution_count": 26,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 493103,
          "sourceId": 916706,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30664,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}